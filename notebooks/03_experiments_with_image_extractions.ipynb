{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy import VideoFileClip\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, List\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "from difflib import SequenceMatcher\n",
    "import json\n",
    "from nltk.translate.bleu_score import sentence_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_seconds(timestamp, fps=30):\n",
    "    hh, mm, ss, ff = map(int, timestamp.split(':'))\n",
    "    total_seconds = hh * 3600 + mm * 60 + ss + ff / fps\n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function for extracting screenshots in certain time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_screenshots_and_processed_df(video_id):\n",
    "    def extract_screenshots(video_path, timestamps, output_folder):\n",
    "        # Check if the output folder exists, if not, create it\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        \n",
    "        video = VideoFileClip(video_path)\n",
    "        screenshot_paths = []\n",
    "\n",
    "        # Iterate through timestamps\n",
    "        for index, timestamp in enumerate(timestamps):\n",
    "            # Set the video to the specified timestamp\n",
    "            try:\n",
    "                timestamp_float = timestamp_to_seconds(timestamp)\n",
    "                frame = video.get_frame(timestamp_float)  # Ensure timestamp is a float\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting frame at timestamp {timestamp} : {e}\")\n",
    "                screenshot_paths.append(None)\n",
    "                continue  # Skip to the next timestamp if there's an error\n",
    "\n",
    "            # Convert the frame to BGR format (OpenCV uses BGR)\n",
    "            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            print(f\"Frame Shape: {frame_bgr.shape}, Type: {frame_bgr.dtype}\")\n",
    "\n",
    "            # Save the screenshot\n",
    "            output_path = f\"{output_folder}/screenshot_{index+1}.png\"\n",
    "            success = cv2.imwrite(output_path, frame_bgr)\n",
    "            if success:\n",
    "                print(f\"Screenshot saved: {output_path}\")\n",
    "                screenshot_paths.append(output_path)\n",
    "            else:\n",
    "                print(f\"Failed to save screenshot: {output_path}\")\n",
    "                screenshot_paths.append(None)\n",
    "\n",
    "        # Close the video file\n",
    "        video.close()\n",
    "        return screenshot_paths\n",
    "\n",
    "    def process_num(n):\n",
    "        return '0' + str(n) if n < 10 else str(n)\n",
    "\n",
    "    def process_timestamps(timestamps):\n",
    "        res = []\n",
    "        for ts in timestamps: \n",
    "            ts = ts.split(' ')\n",
    "            first = int(ts[0][-2:])\n",
    "            second = int(ts[1][-2:])\n",
    "            mid = round(abs(int(first) - int(second)) / 2)\n",
    "            millisec = process_num(first+mid)\n",
    "            res.append(ts[0][:-2] + millisec)\n",
    "        return res\n",
    "\n",
    "    # Load your dataset (assuming it's a CSV file with 'second' and 'video_link' columns)\n",
    "    df = pd.read_csv(f'./data/{video_id}/transcript_{video_id}.csv')\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    # Extract timestamps and video link\n",
    "    timestamps_unprocessed = df['Zeit'].tolist()[1:]\n",
    "    video_link = df['video_src'].iloc[0]  # Assuming all rows have the same video link\n",
    "\n",
    "    # Specify the output folder for screenshots\n",
    "    output_folder = f'./data/{video_id}/screenshots'\n",
    "\n",
    "    processed_timestamps = process_timestamps(timestamps_unprocessed)\n",
    "    \n",
    "    # Ensure the lengths match\n",
    "    if len(processed_timestamps) != len(timestamps_unprocessed):\n",
    "        raise ValueError(\"Processed timestamps length does not match unprocessed timestamps length\")\n",
    "\n",
    "    screenshot_paths = extract_screenshots(video_link, processed_timestamps, output_folder)\n",
    "\n",
    "    # Ensure the lengths match\n",
    "    if len(screenshot_paths) != len(df) - 1:  # Adjust for the header row\n",
    "        # Adjust the length of screenshot_paths to match the DataFrame\n",
    "        screenshot_paths += [None] * ((len(df) - 1) - len(screenshot_paths))\n",
    "\n",
    "    # Generate a DataFrame with the required information\n",
    "    df_processed = df.iloc[1:][['Zeit', 'Übersetzung', 'Lexem/Gebärde', 'Lexem/Gebärde.1', 'Mund', 'video_src', 'video_id']].copy()\n",
    "    df_processed['processed_timestamps'] = processed_timestamps\n",
    "    df_processed['screenshot_path'] = screenshot_paths\n",
    "\n",
    "    # Group by 'Übersetzung'\n",
    "    df_grouped = df_processed.groupby('Übersetzung').agg({\n",
    "        'Zeit': list,\n",
    "        'Lexem/Gebärde': list,\n",
    "        'Lexem/Gebärde.1': list,\n",
    "        'Mund': list,\n",
    "        'video_src': 'first',\n",
    "        'video_id': 'first',\n",
    "        'processed_timestamps': list,\n",
    "        'screenshot_path': list\n",
    "    }).reset_index()\n",
    "\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = '1176340'\n",
    "df_grouped = get_screenshots_and_processed_df(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.to_json(f'./data/{video_id}/processed_transcript_{video_id}.json', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Calculate tokens**\n",
    "    - According to: https://community.openai.com/t/how-do-i-calculate-image-tokens-in-gpt4-vision/492318/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 425\n",
      "Total Image Tokens: 1516825\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from math import ceil\n",
    "\n",
    "def resize(width, height):\n",
    "    if width > 1024 or height > 1024:\n",
    "        if width > height:\n",
    "            height = int(height * 1024 / width)\n",
    "            width = 1024\n",
    "        else:\n",
    "            width = int(width * 1024 / height)\n",
    "            height = 1024\n",
    "    return width, height\n",
    "\n",
    "def count_image_tokens(width: int, height: int):\n",
    "    width, height = resize(width, height)\n",
    "    h = ceil(height / 512)\n",
    "    w = ceil(width / 512)\n",
    "    total = 85 + 170 * h * w\n",
    "    return total\n",
    "\n",
    "def calculate_tokens_from_image(src: str):\n",
    "    with Image.open(src) as img:\n",
    "        width, height = img.size\n",
    "    return count_image_tokens(width, height)\n",
    "\n",
    "# Example usage\n",
    "src = './data/1176340/screenshots/screenshot_1.png'\n",
    "tokens = calculate_tokens_from_image(src)\n",
    "print(f'Tokens: {tokens}')\n",
    "total_image_tokens = 3569*tokens\n",
    "print(f'Total Image Tokens: {total_image_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos: 423\n",
      "Total rows: 746367\n",
      "Average rows per transcript: 1764.4609929078015\n"
     ]
    }
   ],
   "source": [
    "def calculate_transcript_stats(data_dir='./data'):\n",
    "    total_rows = 0\n",
    "    transcript_counts = []\n",
    "    total_videos = 0\n",
    "\n",
    "    for folder_name in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            transcript_path = os.path.join(folder_path, f'transcript_{folder_name}.csv')\n",
    "            if os.path.exists(transcript_path):\n",
    "                df = pd.read_csv(transcript_path)\n",
    "                row_count = len(df)\n",
    "                total_rows += row_count\n",
    "                transcript_counts.append(row_count)\n",
    "                total_videos += 1\n",
    "\n",
    "    average_rows = total_rows / len(transcript_counts) if transcript_counts else 0\n",
    "    return total_rows, average_rows, total_videos\n",
    "\n",
    "# Example usage\n",
    "total_rows, average_rows, total_videos = calculate_transcript_stats()\n",
    "print(f'Total videos: {total_videos}')\n",
    "print(f'Total rows: {total_rows}')\n",
    "print(f'Average rows per transcript: {average_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function to call open ai with the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_path, prompt, model=\"gpt-4o\"):\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Analyze the image and provide insights.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"high\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Prompt that will be used**\n",
    "    - tokens: 114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prompt Tokens: 406866\n",
      "Total tokens used for the image and prompt: 1923691\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    I have an image with two people using German Sign Language (DGS). \n",
    "    Please identify the DGS glosses based on the hand movements without \n",
    "    interpreting the meaning. I only want the gloss, the direct word \n",
    "    translation in German, the person (either 'left' or 'right'), and \n",
    "    the hand used (either 'left' or 'right'). Provide the information \n",
    "    in the following JSON format:\n",
    "\n",
    "    {\n",
    "        \"gloss\": \"\",\n",
    "        \"word\": \"\",\n",
    "        \"person\": \"\",\n",
    "        \"hand\": \"\"\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "prompt_tokens = 114\n",
    "total_prompt_tokens = 3569*prompt_tokens\n",
    "print(f'Total Prompt Tokens: {total_prompt_tokens}')\n",
    "print(f\"Total tokens used for the image and prompt: {total_image_tokens + total_prompt_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with images\n",
    "- Sample taken from video: 1176340"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Import dataset with images and the sources to images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Übersetzung</th>\n",
       "      <th>Zeit</th>\n",
       "      <th>Lexem/Gebärde</th>\n",
       "      <th>Lexem/Gebärde.1</th>\n",
       "      <th>Mund</th>\n",
       "      <th>video_src</th>\n",
       "      <th>video_id</th>\n",
       "      <th>processed_timestamps</th>\n",
       "      <th>screenshot_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aber das ist eigentlich auch egal, weil ich de...</td>\n",
       "      <td>[00:00:34:01 00:00:34:09, 00:00:34:09 00:00:34...</td>\n",
       "      <td>[None, EGAL3*, None, $GEST-ABWINKEN1^*, None, ...</td>\n",
       "      <td>[None, EGAL3*, None, $GEST-ABWINKEN1^*, None, ...</td>\n",
       "      <td>[None, egal, None, None, None, da, None, mut, ...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:00:34:05, 00:00:34:12, 00:00:34:18, 00:00:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_198.png...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aber was?</td>\n",
       "      <td>[00:03:37:13 00:03:37:19, 00:03:37:19 00:03:38...</td>\n",
       "      <td>[None, $ORAL^, None]</td>\n",
       "      <td>[None, $ORAL^, None]</td>\n",
       "      <td>[None, ??, None]</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:03:37:16, 00:03:37:21, 00:03:38:16]</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_1148.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ach ja, das war mit dir zusammen.</td>\n",
       "      <td>[00:02:58:28 00:02:58:41, 00:02:58:41 00:02:58...</td>\n",
       "      <td>[None, None, DU1, None, None, UNTER1A^*, None,...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:02:58:34, 00:02:58:45, 00:02:58:72, 00:02:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_958.png...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Als meine Schwester dann wegging, kam daraufhi...</td>\n",
       "      <td>[00:06:35:17 00:06:35:21, 00:06:35:21 00:06:35...</td>\n",
       "      <td>[$INDEX1, None, SCHWESTER1A*, None, PLÖTZLICH4...</td>\n",
       "      <td>[None, None, SCHWESTER1A*, None, None, None, N...</td>\n",
       "      <td>[None, None, schwester, None, [MG], None, [MG]...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:06:35:19, 00:06:35:24, 00:06:35:31, 00:06:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_2016.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Als meine Schwester und ich klein waren/</td>\n",
       "      <td>[00:02:01:05 00:02:01:13, 00:02:01:13 00:02:01...</td>\n",
       "      <td>[None, GRUND4B*, None, $INDEX1, $INDEX1, None,...</td>\n",
       "      <td>[None, GRUND4B*, None, None, None, None, None,...</td>\n",
       "      <td>[None, grund, None, None, None, None, None, No...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:02:01:09, 00:02:01:18, 00:02:01:27, 00:02:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_658.png...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Übersetzung  \\\n",
       "0  Aber das ist eigentlich auch egal, weil ich de...   \n",
       "1                                          Aber was?   \n",
       "2                  Ach ja, das war mit dir zusammen.   \n",
       "3  Als meine Schwester dann wegging, kam daraufhi...   \n",
       "4           Als meine Schwester und ich klein waren/   \n",
       "\n",
       "                                                Zeit  \\\n",
       "0  [00:00:34:01 00:00:34:09, 00:00:34:09 00:00:34...   \n",
       "1  [00:03:37:13 00:03:37:19, 00:03:37:19 00:03:38...   \n",
       "2  [00:02:58:28 00:02:58:41, 00:02:58:41 00:02:58...   \n",
       "3  [00:06:35:17 00:06:35:21, 00:06:35:21 00:06:35...   \n",
       "4  [00:02:01:05 00:02:01:13, 00:02:01:13 00:02:01...   \n",
       "\n",
       "                                       Lexem/Gebärde  \\\n",
       "0  [None, EGAL3*, None, $GEST-ABWINKEN1^*, None, ...   \n",
       "1                               [None, $ORAL^, None]   \n",
       "2  [None, None, DU1, None, None, UNTER1A^*, None,...   \n",
       "3  [$INDEX1, None, SCHWESTER1A*, None, PLÖTZLICH4...   \n",
       "4  [None, GRUND4B*, None, $INDEX1, $INDEX1, None,...   \n",
       "\n",
       "                                     Lexem/Gebärde.1  \\\n",
       "0  [None, EGAL3*, None, $GEST-ABWINKEN1^*, None, ...   \n",
       "1                               [None, $ORAL^, None]   \n",
       "2  [None, None, None, None, None, None, None, Non...   \n",
       "3  [None, None, SCHWESTER1A*, None, None, None, N...   \n",
       "4  [None, GRUND4B*, None, None, None, None, None,...   \n",
       "\n",
       "                                                Mund  \\\n",
       "0  [None, egal, None, None, None, da, None, mut, ...   \n",
       "1                                   [None, ??, None]   \n",
       "2  [None, None, None, None, None, None, None, Non...   \n",
       "3  [None, None, schwester, None, [MG], None, [MG]...   \n",
       "4  [None, grund, None, None, None, None, None, No...   \n",
       "\n",
       "                                           video_src  video_id  \\\n",
       "0  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "1  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "2  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "3  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "4  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "\n",
       "                                processed_timestamps  \\\n",
       "0  [00:00:34:05, 00:00:34:12, 00:00:34:18, 00:00:...   \n",
       "1            [00:03:37:16, 00:03:37:21, 00:03:38:16]   \n",
       "2  [00:02:58:34, 00:02:58:45, 00:02:58:72, 00:02:...   \n",
       "3  [00:06:35:19, 00:06:35:24, 00:06:35:31, 00:06:...   \n",
       "4  [00:02:01:09, 00:02:01:18, 00:02:01:27, 00:02:...   \n",
       "\n",
       "                                     screenshot_path  \n",
       "0  [./data/1176340/screenshots/screenshot_198.png...  \n",
       "1  [./data/1176340/screenshots/screenshot_1148.pn...  \n",
       "2  [./data/1176340/screenshots/screenshot_958.png...  \n",
       "3  [./data/1176340/screenshots/screenshot_2016.pn...  \n",
       "4  [./data/1176340/screenshots/screenshot_658.png...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_images_df = pd.read_json('./data/1176340/processed_transcript_1176340.json')\n",
    "grouped_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_images_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Get sample of 10 sentences**\n",
    "    - Use 4 as the seed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Übersetzung</th>\n",
       "      <th>Zeit</th>\n",
       "      <th>Lexem/Gebärde</th>\n",
       "      <th>Lexem/Gebärde.1</th>\n",
       "      <th>Mund</th>\n",
       "      <th>video_src</th>\n",
       "      <th>video_id</th>\n",
       "      <th>processed_timestamps</th>\n",
       "      <th>screenshot_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Ich kann bei der Arbeit nicht durchgehend so t...</td>\n",
       "      <td>[00:01:35:00 00:01:35:08, 00:01:35:08 00:01:35...</td>\n",
       "      <td>[None, ICH1, None, ARBEITEN1*, None, IMMER1C, ...</td>\n",
       "      <td>[None, None, None, ARBEITEN1*, None, None, Non...</td>\n",
       "      <td>[None, None, None, arbeite, None, immer, None,...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:01:35:04, 00:01:35:10, 00:01:35:13, 00:01:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_550.png...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Es ist auch eine schöne Erinnerung, wie wir fr...</td>\n",
       "      <td>[00:03:42:04 00:03:42:11, 00:03:42:11 00:03:42...</td>\n",
       "      <td>[None, SCHÖN1A*, None, WAR1*, None, JA1A, None...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>[None, None, None, war, None, ja, None, schön,...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:03:42:08, 00:03:42:15, 00:03:42:20, 00:03:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_1155.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Sie wollten das zunächst erstmal unter sich be...</td>\n",
       "      <td>[00:10:38:40 00:10:38:41, 00:10:38:41 00:10:39...</td>\n",
       "      <td>[None, $GEST^, None, WIMMELN1^*, None, BITTE1A...</td>\n",
       "      <td>[None, $GEST^, None, WIMMELN1^*, None, None, N...</td>\n",
       "      <td>[None, None, None, None, None, [MG], None, Non...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:10:38:40, 00:10:38:55, 00:10:39:19, 00:10:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_3207.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Ich blieb zu Hause.</td>\n",
       "      <td>[00:10:25:10 00:10:25:11, 00:10:25:11 00:10:25...</td>\n",
       "      <td>[None, ICH1, None, BLEIBEN2*, None]</td>\n",
       "      <td>[None, None, None, None, None]</td>\n",
       "      <td>[None, None, None, bleibe, None]</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:10:25:10, 00:10:25:15, 00:10:25:23, 00:10:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_3129.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Für mich war es wichtig, dass ich mich mit mei...</td>\n",
       "      <td>[00:06:09:19 00:06:09:27, 00:06:09:27 00:06:09...</td>\n",
       "      <td>[None, ICH1, None, WICHTIG1, None, ICH1, None,...</td>\n",
       "      <td>[None, None, None, WICHTIG1, None, None, None,...</td>\n",
       "      <td>[None, [MG], None, wichtig, None, schwester, s...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:06:09:23, 00:06:09:33, 00:06:09:42, 00:06:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_1849.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Wenn wir gebärdeten, machte er kleine Fehler u...</td>\n",
       "      <td>[00:06:48:40 00:06:48:48, 00:06:48:48 00:06:49...</td>\n",
       "      <td>[None, VERGEBÄRDEN2*, None, ICH1, None]</td>\n",
       "      <td>[None, VERGEBÄRDEN2*, None, None, None]</td>\n",
       "      <td>[None, [MG] schief, None, None, None]</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:06:48:44, 00:06:48:58, 00:06:49:31, 00:06:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_2109.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Sie ist meine Schwester/</td>\n",
       "      <td>[00:06:38:37 00:06:38:45, 00:06:38:45 00:06:38...</td>\n",
       "      <td>[None, SCHWESTER1A*, None, MEIN1, None, SCHWES...</td>\n",
       "      <td>[None, SCHWESTER1A*, None, None, None, SCHWEST...</td>\n",
       "      <td>[None, sch{wester}, None, meine, None, schwest...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:06:38:41, 00:06:38:47, 00:06:38:71, 00:06:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_2042.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Also über meine Firma, da habe ich 2006 zum er...</td>\n",
       "      <td>[00:00:12:21 00:00:12:29, 00:00:12:29 00:00:12...</td>\n",
       "      <td>[None, FIRMA1B*, None, ZUSAMMENHANG1A*, None, ...</td>\n",
       "      <td>[None, None, None, ZUSAMMENHANG1A*, None, None...</td>\n",
       "      <td>[None, zusammenhang, zusammenhang, zusammenhan...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:00:12:25, 00:00:12:33, 00:00:12:40, 00:00:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_69.png,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Zuerst waren wir zusammen in Schleswig, bis si...</td>\n",
       "      <td>[00:02:09:26 00:02:09:33, 00:02:09:33 00:02:09...</td>\n",
       "      <td>[None, SCHLESWIG1*, None, ZUERST1A*, None, SCH...</td>\n",
       "      <td>[None, None, None, None, None, None, None, ZUS...</td>\n",
       "      <td>[None, schleswig, None, zuerst, None, schleswi...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:02:09:30, 00:02:09:39, 00:02:09:65, 00:02:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_721.png...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Ich beginne das Thema von Anfang an, so wie bi...</td>\n",
       "      <td>[00:00:07:48 00:00:08:11, 00:00:08:11 00:00:08...</td>\n",
       "      <td>[None, ÜBER1, None, THEMA1*, None, ANFANG1A*, ...</td>\n",
       "      <td>[None, None, None, None, None, ANFANG1A*, None...</td>\n",
       "      <td>[None, über, None, thema, None, anfangen, anfa...</td>\n",
       "      <td>https://www.sign-lang.uni-hamburg.de/meinedgs_...</td>\n",
       "      <td>1176340</td>\n",
       "      <td>[00:00:07:66, 00:00:08:13, 00:00:08:18, 00:00:...</td>\n",
       "      <td>[./data/1176340/screenshots/screenshot_43.png,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Übersetzung  \\\n",
       "134  Ich kann bei der Arbeit nicht durchgehend so t...   \n",
       "83   Es ist auch eine schöne Erinnerung, wie wir fr...   \n",
       "218  Sie wollten das zunächst erstmal unter sich be...   \n",
       "118                                Ich blieb zu Hause.   \n",
       "101  Für mich war es wichtig, dass ich mich mit mei...   \n",
       "242  Wenn wir gebärdeten, machte er kleine Fehler u...   \n",
       "215                           Sie ist meine Schwester/   \n",
       "6    Also über meine Firma, da habe ich 2006 zum er...   \n",
       "258  Zuerst waren wir zusammen in Schleswig, bis si...   \n",
       "108  Ich beginne das Thema von Anfang an, so wie bi...   \n",
       "\n",
       "                                                  Zeit  \\\n",
       "134  [00:01:35:00 00:01:35:08, 00:01:35:08 00:01:35...   \n",
       "83   [00:03:42:04 00:03:42:11, 00:03:42:11 00:03:42...   \n",
       "218  [00:10:38:40 00:10:38:41, 00:10:38:41 00:10:39...   \n",
       "118  [00:10:25:10 00:10:25:11, 00:10:25:11 00:10:25...   \n",
       "101  [00:06:09:19 00:06:09:27, 00:06:09:27 00:06:09...   \n",
       "242  [00:06:48:40 00:06:48:48, 00:06:48:48 00:06:49...   \n",
       "215  [00:06:38:37 00:06:38:45, 00:06:38:45 00:06:38...   \n",
       "6    [00:00:12:21 00:00:12:29, 00:00:12:29 00:00:12...   \n",
       "258  [00:02:09:26 00:02:09:33, 00:02:09:33 00:02:09...   \n",
       "108  [00:00:07:48 00:00:08:11, 00:00:08:11 00:00:08...   \n",
       "\n",
       "                                         Lexem/Gebärde  \\\n",
       "134  [None, ICH1, None, ARBEITEN1*, None, IMMER1C, ...   \n",
       "83   [None, SCHÖN1A*, None, WAR1*, None, JA1A, None...   \n",
       "218  [None, $GEST^, None, WIMMELN1^*, None, BITTE1A...   \n",
       "118                [None, ICH1, None, BLEIBEN2*, None]   \n",
       "101  [None, ICH1, None, WICHTIG1, None, ICH1, None,...   \n",
       "242            [None, VERGEBÄRDEN2*, None, ICH1, None]   \n",
       "215  [None, SCHWESTER1A*, None, MEIN1, None, SCHWES...   \n",
       "6    [None, FIRMA1B*, None, ZUSAMMENHANG1A*, None, ...   \n",
       "258  [None, SCHLESWIG1*, None, ZUERST1A*, None, SCH...   \n",
       "108  [None, ÜBER1, None, THEMA1*, None, ANFANG1A*, ...   \n",
       "\n",
       "                                       Lexem/Gebärde.1  \\\n",
       "134  [None, None, None, ARBEITEN1*, None, None, Non...   \n",
       "83   [None, None, None, None, None, None, None, Non...   \n",
       "218  [None, $GEST^, None, WIMMELN1^*, None, None, N...   \n",
       "118                     [None, None, None, None, None]   \n",
       "101  [None, None, None, WICHTIG1, None, None, None,...   \n",
       "242            [None, VERGEBÄRDEN2*, None, None, None]   \n",
       "215  [None, SCHWESTER1A*, None, None, None, SCHWEST...   \n",
       "6    [None, None, None, ZUSAMMENHANG1A*, None, None...   \n",
       "258  [None, None, None, None, None, None, None, ZUS...   \n",
       "108  [None, None, None, None, None, ANFANG1A*, None...   \n",
       "\n",
       "                                                  Mund  \\\n",
       "134  [None, None, None, arbeite, None, immer, None,...   \n",
       "83   [None, None, None, war, None, ja, None, schön,...   \n",
       "218  [None, None, None, None, None, [MG], None, Non...   \n",
       "118                   [None, None, None, bleibe, None]   \n",
       "101  [None, [MG], None, wichtig, None, schwester, s...   \n",
       "242              [None, [MG] schief, None, None, None]   \n",
       "215  [None, sch{wester}, None, meine, None, schwest...   \n",
       "6    [None, zusammenhang, zusammenhang, zusammenhan...   \n",
       "258  [None, schleswig, None, zuerst, None, schleswi...   \n",
       "108  [None, über, None, thema, None, anfangen, anfa...   \n",
       "\n",
       "                                             video_src  video_id  \\\n",
       "134  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "83   https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "218  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "118  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "101  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "242  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "215  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "6    https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "258  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "108  https://www.sign-lang.uni-hamburg.de/meinedgs_...   1176340   \n",
       "\n",
       "                                  processed_timestamps  \\\n",
       "134  [00:01:35:04, 00:01:35:10, 00:01:35:13, 00:01:...   \n",
       "83   [00:03:42:08, 00:03:42:15, 00:03:42:20, 00:03:...   \n",
       "218  [00:10:38:40, 00:10:38:55, 00:10:39:19, 00:10:...   \n",
       "118  [00:10:25:10, 00:10:25:15, 00:10:25:23, 00:10:...   \n",
       "101  [00:06:09:23, 00:06:09:33, 00:06:09:42, 00:06:...   \n",
       "242  [00:06:48:44, 00:06:48:58, 00:06:49:31, 00:06:...   \n",
       "215  [00:06:38:41, 00:06:38:47, 00:06:38:71, 00:06:...   \n",
       "6    [00:00:12:25, 00:00:12:33, 00:00:12:40, 00:00:...   \n",
       "258  [00:02:09:30, 00:02:09:39, 00:02:09:65, 00:02:...   \n",
       "108  [00:00:07:66, 00:00:08:13, 00:00:08:18, 00:00:...   \n",
       "\n",
       "                                       screenshot_path  \n",
       "134  [./data/1176340/screenshots/screenshot_550.png...  \n",
       "83   [./data/1176340/screenshots/screenshot_1155.pn...  \n",
       "218  [./data/1176340/screenshots/screenshot_3207.pn...  \n",
       "118  [./data/1176340/screenshots/screenshot_3129.pn...  \n",
       "101  [./data/1176340/screenshots/screenshot_1849.pn...  \n",
       "242  [./data/1176340/screenshots/screenshot_2109.pn...  \n",
       "215  [./data/1176340/screenshots/screenshot_2042.pn...  \n",
       "6    [./data/1176340/screenshots/screenshot_69.png,...  \n",
       "258  [./data/1176340/screenshots/screenshot_721.png...  \n",
       "108  [./data/1176340/screenshots/screenshot_43.png,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_number = 4\n",
    "sampled_df = grouped_images_df.sample(n=10, random_state=seed_number)\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ungroup dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame with the desired columns\n",
    "ungrouped_df = pd.DataFrame(columns=['Zeit', 'Lexem/Gebärde', 'Lexem/Gebärde.1', 'Mund', 'processed_timestamps', 'screenshot_path', 'Übersetzung', 'video_id'])\n",
    "ungrouped_list = []\n",
    "\n",
    "# Iterate over the sampled DataFrame and ungroup the data\n",
    "for index, row in grouped_images_df.iterrows():\n",
    "    group_cols = ['Zeit', 'Lexem/Gebärde', 'Lexem/Gebärde.1', 'Mund', 'processed_timestamps', 'screenshot_path']\n",
    "    ubersetzung = row['Übersetzung']\n",
    "    print(\"video: \", row['video_id'])\n",
    "    print(\"Translation words number: \", len(ubersetzung.split(' ')))\n",
    "    print(\"Zeit number: \", len(row['Zeit']))\n",
    "    print(\"glosses number: \", len([x for x in row['Lexem/Gebärde']+row['Lexem/Gebärde.1'] if x is not None]))\n",
    "    ungrouped_per_sentence = pd.DataFrame(columns=['Zeit', 'Lexem/Gebärde', 'Lexem/Gebärde.1', 'Mund', 'processed_timestamps', 'screenshot_path', 'Übersetzung', 'video_id'])\n",
    "    for i in range(len(row['Zeit'])):\n",
    "        group_data = {col: row[col][i] for col in group_cols}\n",
    "        group_data['Übersetzung'] = row['Übersetzung']\n",
    "        group_data['video_id'] = row['video_id']\n",
    "        \n",
    "        # Append the ungrouped data to the DataFrame\n",
    "        ungrouped_df = pd.concat([ungrouped_df, pd.DataFrame([group_data])], ignore_index=True)\n",
    "        ungrouped_per_sentence = pd.concat([ungrouped_per_sentence, pd.DataFrame([group_data])], ignore_index=True)\n",
    "    ungrouped_list.append(ungrouped_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zeit</th>\n",
       "      <th>Lexem/Gebärde</th>\n",
       "      <th>Lexem/Gebärde.1</th>\n",
       "      <th>Mund</th>\n",
       "      <th>processed_timestamps</th>\n",
       "      <th>screenshot_path</th>\n",
       "      <th>Übersetzung</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:34:01 00:00:34:09</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00:34:05</td>\n",
       "      <td>./data/1176340/screenshots/screenshot_198.png</td>\n",
       "      <td>Aber das ist eigentlich auch egal, weil ich de...</td>\n",
       "      <td>1176340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:34:09 00:00:34:15</td>\n",
       "      <td>EGAL3*</td>\n",
       "      <td>EGAL3*</td>\n",
       "      <td>egal</td>\n",
       "      <td>00:00:34:12</td>\n",
       "      <td>./data/1176340/screenshots/screenshot_199.png</td>\n",
       "      <td>Aber das ist eigentlich auch egal, weil ich de...</td>\n",
       "      <td>1176340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:34:15 00:00:34:21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00:34:18</td>\n",
       "      <td>./data/1176340/screenshots/screenshot_200.png</td>\n",
       "      <td>Aber das ist eigentlich auch egal, weil ich de...</td>\n",
       "      <td>1176340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:34:21 00:00:34:30</td>\n",
       "      <td>$GEST-ABWINKEN1^*</td>\n",
       "      <td>$GEST-ABWINKEN1^*</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00:34:25</td>\n",
       "      <td>./data/1176340/screenshots/screenshot_201.png</td>\n",
       "      <td>Aber das ist eigentlich auch egal, weil ich de...</td>\n",
       "      <td>1176340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:34:30 00:00:34:35</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:00:34:32</td>\n",
       "      <td>./data/1176340/screenshots/screenshot_202.png</td>\n",
       "      <td>Aber das ist eigentlich auch egal, weil ich de...</td>\n",
       "      <td>1176340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Zeit      Lexem/Gebärde    Lexem/Gebärde.1  Mund  \\\n",
       "0  00:00:34:01 00:00:34:09               None               None  None   \n",
       "1  00:00:34:09 00:00:34:15             EGAL3*             EGAL3*  egal   \n",
       "2  00:00:34:15 00:00:34:21               None               None  None   \n",
       "3  00:00:34:21 00:00:34:30  $GEST-ABWINKEN1^*  $GEST-ABWINKEN1^*  None   \n",
       "4  00:00:34:30 00:00:34:35               None               None  None   \n",
       "\n",
       "  processed_timestamps                                screenshot_path  \\\n",
       "0          00:00:34:05  ./data/1176340/screenshots/screenshot_198.png   \n",
       "1          00:00:34:12  ./data/1176340/screenshots/screenshot_199.png   \n",
       "2          00:00:34:18  ./data/1176340/screenshots/screenshot_200.png   \n",
       "3          00:00:34:25  ./data/1176340/screenshots/screenshot_201.png   \n",
       "4          00:00:34:32  ./data/1176340/screenshots/screenshot_202.png   \n",
       "\n",
       "                                         Übersetzung video_id  \n",
       "0  Aber das ist eigentlich auch egal, weil ich de...  1176340  \n",
       "1  Aber das ist eigentlich auch egal, weil ich de...  1176340  \n",
       "2  Aber das ist eigentlich auch egal, weil ich de...  1176340  \n",
       "3  Aber das ist eigentlich auch egal, weil ich de...  1176340  \n",
       "4  Aber das ist eigentlich auch egal, weil ich de...  1176340  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ungrouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27864"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ungrouped_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with image sequencies\n",
    "- Few sentences sample\n",
    "- Send vocabulary dictioonary to model as context, then send sentence (sequence of images) for its translation\n",
    "- Calculate or measure accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Separate screenshots by left - right**\n",
    "- Generate Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gloss vocabulary: ./data/1176340/gloss_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Crear lista para el nuevo dataset\n",
    "new_data = []\n",
    "\n",
    "# Carpeta donde se guardarán las imágenes divididas\n",
    "output_folder = \"./data/1176340/screenshots_divided/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Procesar cada fila del DataFrame\n",
    "for index, row in ungrouped_df.iterrows():\n",
    "    left_gloss = row[\"Lexem/Gebärde\"]\n",
    "    right_gloss = row[\"Lexem/Gebärde.1\"]\n",
    "    screenshot_path = row[\"screenshot_path\"]\n",
    "    timestamp = row[\"processed_timestamps\"]\n",
    "    sentence = row[\"Übersetzung\"]\n",
    "\n",
    "    # Verificar si el gloss existe\n",
    "    left_exists = pd.notna(left_gloss)\n",
    "    right_exists = pd.notna(right_gloss)\n",
    "\n",
    "    # Si no hay gloss en ninguna columna, pasar a la siguiente fila\n",
    "    if not left_exists and not right_exists:\n",
    "        continue\n",
    "\n",
    "    # Verificar si la imagen original existe\n",
    "    if not os.path.exists(screenshot_path):\n",
    "        print(f\"Imagen no encontrada: {screenshot_path}\")\n",
    "        continue\n",
    "\n",
    "    # Abrir imagen y dividir en dos\n",
    "    with Image.open(screenshot_path) as img:\n",
    "        width, height = img.size\n",
    "\n",
    "        # Guardar solo si el gloss existe\n",
    "        if left_exists:\n",
    "            left_half = img.crop((0, 0, width // 2, height))\n",
    "            left_path = os.path.join(output_folder, f\"gloss_{index}_left.png\")\n",
    "            left_half.save(left_path)\n",
    "            new_data.append([sentence, left_gloss, \"left\", screenshot_path, left_path, timestamp])\n",
    "\n",
    "        if right_exists:\n",
    "            right_half = img.crop((width // 2, 0, width, height))\n",
    "            right_path = os.path.join(output_folder, f\"gloss_{index}_right.png\")\n",
    "            right_half.save(right_path)\n",
    "            new_data.append([sentence, right_gloss, \"right\", screenshot_path, right_path, timestamp])\n",
    "\n",
    "# Crear DataFrame ordenado por timestamp\n",
    "columns = [\"sentence\", \"gloss\", \"position\", \"original_path\", \"new_path\", \"timestamp\"]\n",
    "sorted_df = pd.DataFrame(new_data, columns=columns).sort_values(by=\"timestamp\")\n",
    "\n",
    "# Guardar en CSV\n",
    "sorted_df.to_csv(\"./data/1176340/gloss_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Gloss vocabulary: ./data/1176340/gloss_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = pd.read_csv(\"./data/1176340/gloss_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14364"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Create vocabulary dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary_dictionary(df_ungrouped: pd.DataFrame) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Create a vocabulary dictionary with glosses and associated images.\n",
    "    \n",
    "    Args:\n",
    "        df_ungrouped: DataFrame with ungrouped sign language data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with glosses as keys and associated data (excluding the gloss column) as values.\n",
    "    \"\"\"\n",
    "    vocabulary = {}\n",
    "\n",
    "    # Obtener los glosses únicos\n",
    "    unique_glosses = set(df_ungrouped[\"gloss\"].dropna())\n",
    "\n",
    "    for gloss in unique_glosses:\n",
    "        # Filtrar DataFrame por gloss actual\n",
    "        grouped_by_gloss = df_ungrouped[df_ungrouped[\"gloss\"] == gloss]\n",
    "\n",
    "        # Eliminar la columna \"gloss\" para evitar redundancia\n",
    "        grouped_by_gloss = grouped_by_gloss.drop(columns=[\"gloss\"]).reset_index(drop=True)\n",
    "\n",
    "        # Convertir a diccionario\n",
    "        vocabulary[gloss] = grouped_by_gloss.to_dict(orient=\"records\")\n",
    "\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Create sentences sample to send sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences_sample(df_ungrouped: pd.DataFrame, vocabulary: Dict[str, Dict], seed_number: int = 4, sample_n: int = 10) -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Create a sample of sentences with the sequence of glosses used.\n",
    "\n",
    "    Args:\n",
    "        df_ungrouped: DataFrame with ungrouped sign language data\n",
    "        vocabulary: Dictionary containing glosses and their associated images\n",
    "        seed_number: Random seed for reproducibility\n",
    "        sample_n: Number of sentences to return as a sample\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with sentences, their glosses, other data, and a vocabulary sample for the prompt.\n",
    "    \"\"\"\n",
    "    random.seed(seed_number)\n",
    "    result = {}\n",
    "\n",
    "    # Obtener las oraciones únicas\n",
    "    unique_sentences = list(df_ungrouped[\"sentence\"].dropna().unique())\n",
    "\n",
    "    # Seleccionar solo sample_n oraciones aleatorias\n",
    "    sampled_sentences = random.sample(unique_sentences, min(sample_n, len(unique_sentences)))\n",
    "\n",
    "    for sentence in sampled_sentences:\n",
    "        # Filtrar DataFrame por la oración actual\n",
    "        grouped_by_sentence = df_ungrouped[df_ungrouped[\"sentence\"] == sentence].drop(columns=[\"sentence\"]).reset_index(drop=True)\n",
    "\n",
    "        # Obtener los glosses de la oración\n",
    "        glosses = grouped_by_sentence[\"gloss\"].dropna().tolist()\n",
    "\n",
    "        vocabulary_sample_for_prompt = {}\n",
    "\n",
    "        for gloss in glosses:\n",
    "            if gloss in vocabulary:\n",
    "                df_gloss = pd.DataFrame(vocabulary[gloss])\n",
    "                if \"new_path\" in df_gloss.columns and not df_gloss.empty:\n",
    "                    images_from_gloss = df_gloss[\"new_path\"].dropna().tolist()\n",
    "                    if images_from_gloss:\n",
    "                        selected_image = random.choice(images_from_gloss)\n",
    "                        vocabulary_sample_for_prompt[gloss] = selected_image\n",
    "\n",
    "        # Añadir 4 glosses aleatorios para confundir al LLM\n",
    "        all_glosses = list(vocabulary.keys())\n",
    "        random_glosses = random.sample([g for g in all_glosses if g not in glosses], min(4, len(all_glosses)))\n",
    "\n",
    "        for random_gloss in random_glosses:\n",
    "            df_random_gloss = pd.DataFrame(vocabulary[random_gloss])\n",
    "            if \"new_path\" in df_random_gloss.columns and not df_random_gloss.empty:\n",
    "                images_from_random_gloss = df_random_gloss[\"new_path\"].dropna().tolist()\n",
    "                if images_from_random_gloss:\n",
    "                    vocabulary_sample_for_prompt[random_gloss] = random.choice(images_from_random_gloss)\n",
    "\n",
    "        # Shuffle vocabulary_sample_for_prompt to randomize order\n",
    "        shuffled_vocab_sample = dict(random.sample(list(vocabulary_sample_for_prompt.items()), len(vocabulary_sample_for_prompt)))\n",
    "\n",
    "        # Guardar los datos en el diccionario final\n",
    "        result[sentence] = {\n",
    "            \"data\": grouped_by_sentence.to_dict(orient=\"records\"),\n",
    "            \"vocabulary_sample_for_prompt\": shuffled_vocab_sample\n",
    "        }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Encode an image to base64 string.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        Base64 encoded string of the image or None if the file doesn't exist\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Warning: Image file {image_path} does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Generate vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glosses: 675\n"
     ]
    }
   ],
   "source": [
    "vocabulary_dict = create_vocabulary_dictionary(sorted_df)\n",
    "print(f\"Number of glosses: {len(list(vocabulary_dict))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Generate sentences sample to experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_experiment = create_sentences_sample(sorted_df, vocabulary_dict, seed_number=4, sample_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_glosses_accuracy_nltk(predicted: List[str], actual: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity between predicted and actual sentences using SequenceMatcher.\n",
    "    Returns a percentage match.\n",
    "    \"\"\"\n",
    "    similarity = SequenceMatcher(None, ' '.join(predicted).lower(), ' '.join(actual).lower()).ratio()\n",
    "    return similarity * 100\n",
    "\n",
    "def compute_glosses_accuracy_nltk_bleu(predicted: List[str], actual: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Compute BLEU score between predicted and actual sentences.\n",
    "    Returns a percentage match.\n",
    "    \"\"\"\n",
    "    reference = [actual]\n",
    "    candidate = predicted\n",
    "    score = sentence_bleu(reference, candidate)\n",
    "    return score * 100\n",
    "\n",
    "def translate_german_to_english(client: OpenAI, german_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Translate German text to English using OpenAI API.\n",
    "    \"\"\"\n",
    "    prompt = f\"Translate the following German text to English:\\n\\n{german_text}\\n\\nEnglish translation:\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error translating to English: {str(e)}\"\n",
    "\n",
    "def translate_image_sequence(sample_of_sentences: Dict[str, Dict], sentence_index: int = 0, model: str = \"gpt-4o\") -> Dict:\n",
    "    \"\"\"\n",
    "    Translate a sequence of images to glosses and sentences using OpenAI API.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    glosses = []\n",
    "    sentence_experiment = list(sample_of_sentences)[sentence_index] \n",
    "    sentence = sample_of_sentences[sentence_experiment][\"data\"]\n",
    "    image_vocabulary = sample_of_sentences[sentence_experiment][\"vocabulary_sample_for_prompt\"]\n",
    "    content = [{\"type\": \"text\", \"text\": \"VOCABULARY REFERENCE (Image → Gloss):\"}]\n",
    "    \n",
    "    for i, (gloss, image_path) in enumerate(image_vocabulary.items(), 1):\n",
    "        base64_image = encode_image_to_base64(image_path)\n",
    "        if base64_image:\n",
    "            content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}})\n",
    "            content.append({\"type\": \"text\", \"text\": f\"Vocabulary Image {i}: {gloss}\"})\n",
    "    \n",
    "    content.append({\"type\": \"text\", \"text\": \"\\nSENTENCE TO TRANSLATE (Sequence of Images):\"})\n",
    "    \n",
    "    for i, fragment in enumerate(sentence, 1):\n",
    "        glosses.append(fragment[\"gloss\"])\n",
    "        base64_image = encode_image_to_base64(fragment[\"new_path\"])\n",
    "        if base64_image:\n",
    "            content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}})\n",
    "            content.append({\"type\": \"text\", \"text\": f\"Sentence Image {i}\"})\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    Based on the vocabulary reference images and their corresponding glosses provided above, \n",
    "    analyze the sequence of images representing a sentence and:\n",
    "    \n",
    "    1. Identify which glosses from the vocabulary each image in the sentence corresponds to\n",
    "    2. Translate the sequence of glosses into a coherent German sentence\n",
    "    \n",
    "    Return your response in the following JSON format:\n",
    "    {\n",
    "        \"predicted_glosses\": [\"gloss1\", \"gloss2\", ...],\n",
    "        \"german_translation\": \"German sentence translation\",\n",
    "        \"english_translation\": \"English sentence translation\"\n",
    "    }\n",
    "    \n",
    "    If you're uncertain about any image, make your best guess based on visual similarity to the vocabulary images.\n",
    "    \"\"\"\n",
    "    \n",
    "    content.append({\"type\": \"text\", \"text\": prompt})\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": content}],\n",
    "            max_tokens=1000,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        result[\"expected_glosses\"] = glosses\n",
    "        result[\"image_sequence\"] = [fragment[\"new_path\"] for fragment in sentence]\n",
    "        accuracy_result_sequence_matcher = compute_glosses_accuracy_nltk(result[\"predicted_glosses\"], glosses)\n",
    "        accuracy_result_bleu = compute_glosses_accuracy_nltk_bleu(result[\"predicted_glosses\"], glosses)\n",
    "        result[\"sequence_matcher_accuracy\"] = accuracy_result_sequence_matcher\n",
    "        result[\"bleu_accuracy\"] = accuracy_result_bleu\n",
    "        \n",
    "        # Translate German to English\n",
    "        english_translation = translate_german_to_english(client, sentence_experiment)\n",
    "        result[\"expected_german_english_translation\"] = english_translation\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"expected_glosses\": glosses,\n",
    "            \"predicted_glosses\": result[\"glosses\"],\n",
    "            \"german_translation\": \"Error generating translation\",\n",
    "            \"english_translation\": \"Error generating translation\",\n",
    "            \"sequence_matcher_accuracy\": 0,\n",
    "            \"bleu_accuracy\": 0,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\javie\\Desktop\\ABERDEEN\\RESEARCH\\sign-language-experiment\\venv\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\javie\\Desktop\\ABERDEEN\\RESEARCH\\sign-language-experiment\\venv\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\javie\\Desktop\\ABERDEEN\\RESEARCH\\sign-language-experiment\\venv\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "results_df = []\n",
    "for i in range(len(sample_to_experiment)):\n",
    "    result = translate_image_sequence(sample_to_experiment, sentence_index=i, model=\"gpt-4o-mini\")\n",
    "    result[\"sentence\"] = list(sample_to_experiment)[i]\n",
    "    results_df.append(result)\n",
    "results_df = pd.DataFrame(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_glosses</th>\n",
       "      <th>german_translation</th>\n",
       "      <th>english_translation</th>\n",
       "      <th>expected_glosses</th>\n",
       "      <th>image_sequence</th>\n",
       "      <th>sequence_matcher_accuracy</th>\n",
       "      <th>bleu_accuracy</th>\n",
       "      <th>expected_german_english_translation</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[MEHR1, NUR2A, INHALT3, AUSTAUSCHEN-KOMMUNIKAT...</td>\n",
       "      <td>Mehr nur Inhalt, Austausch und Kommunikation, ...</td>\n",
       "      <td>More just content, exchange and communication,...</td>\n",
       "      <td>[JUNG1*, AUFPASSEN1B^*, AUFPASSEN1B^*, INHALT3...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_797_...</td>\n",
       "      <td>20.895522</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>The youth leader, for example, can initiate a ...</td>\n",
       "      <td>Der Jugendwart kann z.B. initiieren, dass man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[$GEST^, BRUDER1A*, BESCHEID1A*, SCHLIMM3B*, S...</td>\n",
       "      <td>Ich spreche später mit meinem Bruder.</td>\n",
       "      <td>I will talk to my brother later.</td>\n",
       "      <td>[BRUDER1A*, BRUDER1A*, BESCHEID1A*, $GEST^, $G...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_2436...</td>\n",
       "      <td>60.869565</td>\n",
       "      <td>9.283143e-153</td>\n",
       "      <td>My brother said to me, \"Hey, why didn't you te...</td>\n",
       "      <td>Mein Bruder meinte zu mir: „Hey, warum hast du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ICH1, ALLE3]</td>\n",
       "      <td>Ich alle.</td>\n",
       "      <td>I all.</td>\n",
       "      <td>[$INDEX1*, ICH1*]</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_2224...</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>I</td>\n",
       "      <td>Ich/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ICH2, EINFACH3, NICHT3A, MÖGEN4]</td>\n",
       "      <td>Ich mag es nicht einfach.</td>\n",
       "      <td>I do not like it simply.</td>\n",
       "      <td>[GRUND4B*, GRUND4B*, ICH2, KEIN1*, MÖGEN4, NIC...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_778_...</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>1.495451e-230</td>\n",
       "      <td>The reason was that I did not want to sit arou...</td>\n",
       "      <td>Der Grund war der, dass ich nicht rumsitzen un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ZUSAMMENHANG1A^, ICH1, VERLETZUNG1A, TRENNEN2...</td>\n",
       "      <td>Zusammenhang ich Verletzung trennen, wie sozus...</td>\n",
       "      <td>Context I injury separate, how to say.</td>\n",
       "      <td>[DARUM1*, DARUM1*, ICH1, WIE-SOZUSAGEN1*, WIE-...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_1482...</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>3.237241e-230</td>\n",
       "      <td>I burst into tears because I felt hurt.</td>\n",
       "      <td>Ich bin in Tränen ausgebrochen, weil ich mich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[MEINUNG1A, STIMMT1B*, GEHÖREN1^*, MANNSCHAFT1...</td>\n",
       "      <td>Die Meinung stimmt, es gehört zur Mannschaft a...</td>\n",
       "      <td>The opinion is correct; it belongs to the team...</td>\n",
       "      <td>[MANNSCHAFT1*, FUSSBALL1A, FUSSBALL1A, MANNSCH...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_3462...</td>\n",
       "      <td>27.027027</td>\n",
       "      <td>2.535240e-153</td>\n",
       "      <td>We shared the same opinion about the football ...</td>\n",
       "      <td>Über die Fußballmannschaft Bayern München teil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ICH2, AUCH1A, KANN2B, WICHTIG1*, GEBÄRDEN1A*]</td>\n",
       "      <td>Ich kann auch wichtig gebärden.</td>\n",
       "      <td>I can also sign important things.</td>\n",
       "      <td>[ICH2, WICHTIG1*, WICHTIG1*, AUCH1A, CHEF1B, K...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_2601...</td>\n",
       "      <td>44.827586</td>\n",
       "      <td>8.186019e-230</td>\n",
       "      <td>It is also important to me that my boss can us...</td>\n",
       "      <td>Mir ist es auch wichtig, dass mein Chef gebärd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[HOFFEN1A*, ICH2, WARUM1*, RICHTIG1A*, MANCHMAL1]</td>\n",
       "      <td>Ich hoffe, warum ist es manchmal richtig?</td>\n",
       "      <td>I hope, why is it sometimes right?</td>\n",
       "      <td>[ICH2, GEBÄRDEN1A*, GEBÄRDEN1A*, HOFFEN1A*, FÖ...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_1592...</td>\n",
       "      <td>32.380952</td>\n",
       "      <td>1.186218e-229</td>\n",
       "      <td>I gestured with them and hoped to motivate the...</td>\n",
       "      <td>Ich gebärdete mit ihnen und hoffte, sie dadurc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[SCHWER1A, MEISTENS1B, DASSELBE2A, VERLETZUNG1...</td>\n",
       "      <td>Es ist meistens dasselbe und sehr schlimm, wen...</td>\n",
       "      <td>It is mostly the same and very bad when one is...</td>\n",
       "      <td>[$GEST^, $GEST^, $PROD*, DASSELBE2A, DASSELBE2...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_2955...</td>\n",
       "      <td>42.372881</td>\n",
       "      <td>9.853445e-230</td>\n",
       "      <td>Should I hold back? That would be something si...</td>\n",
       "      <td>Soll ich mich zurückhalten? Das wäre so etwas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[GLAUBEN2A, UNSICHER1, WIE-VERGLEICH1A, ZUSAMM...</td>\n",
       "      <td>Ich glaube, ich bin unsicher, wie diese Person...</td>\n",
       "      <td>I believe I am uncertain about how this person...</td>\n",
       "      <td>[$INDEX1*, WISSEN2B^*, WIE-VERGLEICH1A*, WIE-V...</td>\n",
       "      <td>[./data/1176340/screenshots_divided/gloss_605_...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>That was like/</td>\n",
       "      <td>Das war wie/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   predicted_glosses  \\\n",
       "0  [MEHR1, NUR2A, INHALT3, AUSTAUSCHEN-KOMMUNIKAT...   \n",
       "1  [$GEST^, BRUDER1A*, BESCHEID1A*, SCHLIMM3B*, S...   \n",
       "2                                      [ICH1, ALLE3]   \n",
       "3                  [ICH2, EINFACH3, NICHT3A, MÖGEN4]   \n",
       "4  [ZUSAMMENHANG1A^, ICH1, VERLETZUNG1A, TRENNEN2...   \n",
       "5  [MEINUNG1A, STIMMT1B*, GEHÖREN1^*, MANNSCHAFT1...   \n",
       "6     [ICH2, AUCH1A, KANN2B, WICHTIG1*, GEBÄRDEN1A*]   \n",
       "7  [HOFFEN1A*, ICH2, WARUM1*, RICHTIG1A*, MANCHMAL1]   \n",
       "8  [SCHWER1A, MEISTENS1B, DASSELBE2A, VERLETZUNG1...   \n",
       "9  [GLAUBEN2A, UNSICHER1, WIE-VERGLEICH1A, ZUSAMM...   \n",
       "\n",
       "                                  german_translation  \\\n",
       "0  Mehr nur Inhalt, Austausch und Kommunikation, ...   \n",
       "1              Ich spreche später mit meinem Bruder.   \n",
       "2                                          Ich alle.   \n",
       "3                          Ich mag es nicht einfach.   \n",
       "4  Zusammenhang ich Verletzung trennen, wie sozus...   \n",
       "5  Die Meinung stimmt, es gehört zur Mannschaft a...   \n",
       "6                    Ich kann auch wichtig gebärden.   \n",
       "7          Ich hoffe, warum ist es manchmal richtig?   \n",
       "8  Es ist meistens dasselbe und sehr schlimm, wen...   \n",
       "9  Ich glaube, ich bin unsicher, wie diese Person...   \n",
       "\n",
       "                                 english_translation  \\\n",
       "0  More just content, exchange and communication,...   \n",
       "1                   I will talk to my brother later.   \n",
       "2                                             I all.   \n",
       "3                           I do not like it simply.   \n",
       "4             Context I injury separate, how to say.   \n",
       "5  The opinion is correct; it belongs to the team...   \n",
       "6                  I can also sign important things.   \n",
       "7                 I hope, why is it sometimes right?   \n",
       "8  It is mostly the same and very bad when one is...   \n",
       "9  I believe I am uncertain about how this person...   \n",
       "\n",
       "                                    expected_glosses  \\\n",
       "0  [JUNG1*, AUFPASSEN1B^*, AUFPASSEN1B^*, INHALT3...   \n",
       "1  [BRUDER1A*, BRUDER1A*, BESCHEID1A*, $GEST^, $G...   \n",
       "2                                  [$INDEX1*, ICH1*]   \n",
       "3  [GRUND4B*, GRUND4B*, ICH2, KEIN1*, MÖGEN4, NIC...   \n",
       "4  [DARUM1*, DARUM1*, ICH1, WIE-SOZUSAGEN1*, WIE-...   \n",
       "5  [MANNSCHAFT1*, FUSSBALL1A, FUSSBALL1A, MANNSCH...   \n",
       "6  [ICH2, WICHTIG1*, WICHTIG1*, AUCH1A, CHEF1B, K...   \n",
       "7  [ICH2, GEBÄRDEN1A*, GEBÄRDEN1A*, HOFFEN1A*, FÖ...   \n",
       "8  [$GEST^, $GEST^, $PROD*, DASSELBE2A, DASSELBE2...   \n",
       "9  [$INDEX1*, WISSEN2B^*, WIE-VERGLEICH1A*, WIE-V...   \n",
       "\n",
       "                                      image_sequence  \\\n",
       "0  [./data/1176340/screenshots_divided/gloss_797_...   \n",
       "1  [./data/1176340/screenshots_divided/gloss_2436...   \n",
       "2  [./data/1176340/screenshots_divided/gloss_2224...   \n",
       "3  [./data/1176340/screenshots_divided/gloss_778_...   \n",
       "4  [./data/1176340/screenshots_divided/gloss_1482...   \n",
       "5  [./data/1176340/screenshots_divided/gloss_3462...   \n",
       "6  [./data/1176340/screenshots_divided/gloss_2601...   \n",
       "7  [./data/1176340/screenshots_divided/gloss_1592...   \n",
       "8  [./data/1176340/screenshots_divided/gloss_2955...   \n",
       "9  [./data/1176340/screenshots_divided/gloss_605_...   \n",
       "\n",
       "   sequence_matcher_accuracy  bleu_accuracy  \\\n",
       "0                  20.895522   0.000000e+00   \n",
       "1                  60.869565  9.283143e-153   \n",
       "2                  33.333333   0.000000e+00   \n",
       "3                  22.500000  1.495451e-230   \n",
       "4                  36.666667  3.237241e-230   \n",
       "5                  27.027027  2.535240e-153   \n",
       "6                  44.827586  8.186019e-230   \n",
       "7                  32.380952  1.186218e-229   \n",
       "8                  42.372881  9.853445e-230   \n",
       "9                  40.000000   0.000000e+00   \n",
       "\n",
       "                 expected_german_english_translation  \\\n",
       "0  The youth leader, for example, can initiate a ...   \n",
       "1  My brother said to me, \"Hey, why didn't you te...   \n",
       "2                                                  I   \n",
       "3  The reason was that I did not want to sit arou...   \n",
       "4            I burst into tears because I felt hurt.   \n",
       "5  We shared the same opinion about the football ...   \n",
       "6  It is also important to me that my boss can us...   \n",
       "7  I gestured with them and hoped to motivate the...   \n",
       "8  Should I hold back? That would be something si...   \n",
       "9                                     That was like/   \n",
       "\n",
       "                                            sentence  \n",
       "0  Der Jugendwart kann z.B. initiieren, dass man ...  \n",
       "1  Mein Bruder meinte zu mir: „Hey, warum hast du...  \n",
       "2                                               Ich/  \n",
       "3  Der Grund war der, dass ich nicht rumsitzen un...  \n",
       "4  Ich bin in Tränen ausgebrochen, weil ich mich ...  \n",
       "5  Über die Fußballmannschaft Bayern München teil...  \n",
       "6  Mir ist es auch wichtig, dass mein Chef gebärd...  \n",
       "7  Ich gebärdete mit ihnen und hoffte, sie dadurc...  \n",
       "8  Soll ich mich zurückhalten? Das wäre so etwas ...  \n",
       "9                                       Das war wie/  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Export results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_json(\"./data/1176340/gloss_dataset_results_gpt4o_mini.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
